{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Прогноз вероятности неврологических проявлений при болезни Вильсона-Коновалова. Линейная логистическая регрессия\n",
    "\n",
    "* Импорт библиотек\n",
    "* Чтение данных\n",
    "* Пропуски в данных\n",
    "* Группы признаков\n",
    "* Отбор признаков для модели\n",
    "* Оптимизация параметров и оценка качества моделей\n",
    "* Выводы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/11707586/python-pandas-how-to-widen-output-display-to-see-more-columns\n",
    "pd.set_option('display.max_columns', 70)   # Настройка отображения данных в Jupyter notebook\n",
    "pd.set_option('display.max_rows', 100)     \n",
    "pd.set_option('precision', 3)\n",
    "pd.set_option('display.width', 1000)\n",
    "pd.set_option('display.height', 1000)\n",
    "np.core.arrayprint._line_width = 100\n",
    "\n",
    "%pylab inline\n",
    "# Visualization and Graphics\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# !conda install seaborn \n",
    "import seaborn as sns\n",
    "plt.rcParams['figure.figsize'] = (7,7)   # (8,6)\n",
    "\n",
    "# conda install -c conda-forge ggplot     # Suggests to down-grade matplotlib and some other packages - rejected\n",
    "#!pip install ggplot                      # Installs OK\n",
    "matplotlib.style.use('ggplot')            # Use ggplot style plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Чтение исходных данных"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Чтение данных из сохранённого файла\n",
    "data_dir = '../data_transforemed/'\n",
    "\n",
    "df_ext = pd.DataFrame()\n",
    "df_ext = pd.read_csv(data_dir + 'Wilson_ext.csv', sep=';', encoding='utf-8') \n",
    "print(df_ext.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Пропуски в данных\n",
    "Заполним пропуски **средними значениями**. <br> Это удобно для выбранного алгоритма."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# В каких колонках есть пропуски?\n",
    "for c in df_ext.columns:\n",
    "    number_of_na = np.sum(df_ext[c].isna())            # Needs Pandas 22.0 or higher\n",
    "    if number_of_na > 0:\n",
    "        print(c, number_of_na, df_ext[c].mean())\n",
    "\n",
    "df = df_ext.fillna(df_ext.mean())                      # Заполним пропуски средними значениями\n",
    "\n",
    "print( df_ext[['TargetHeadRelativeMax', 'BMI']].fillna(df_ext.mean()).head(8) )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Группы признаков\n",
    "Группы выделены в соответствии со смыслом данных, логикой их использования и обработки, форматом представления данных.\n",
    "<br> Группы сформированы в файле `preprocess_data.ipynb`\n",
    "- `target`\n",
    "- `relatives`\n",
    "- `sex`, `sex_cat`\n",
    "- `bmi`, `bmi_scaled`\n",
    "- `symptom`\n",
    "- `cirrhosis`\n",
    "    - `childpugh_dummy`\n",
    "- `debut_age`, `debut_age_scaled`\n",
    "- `debut_organ`\n",
    "- `genetic`\n",
    "- `genetic_dummy`\n",
    "- `genetic__1`, `genetic__2`\n",
    "- `genetic_risk__1`, `genetic_risk__2`\n",
    "- `genetic_risk__1_scaled`, `genetic_risk__2_scaled`\n",
    "- `data`\n",
    "- `exclude`, `exclude_model`\n",
    "\n",
    "<br> Вспомогательные признаки\n",
    "- `num_to_scale`\n",
    "- `num_scaled`\n",
    "- `genetic_risk`\n",
    "- `genetic_risk_scaled`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# !conda install simplejson\n",
    "%run data_to_json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import OrderedDict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_file = open(data_dir + 'features_file.json', 'r')\n",
    "features = json_to_data( features_file.read() )\n",
    "features_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "features['relatives']\n",
    "features['bmi']\n",
    "features['cirrhosis']\n",
    "#print(features)\n",
    "#type(features)\n",
    "\n",
    "for k in features.keys():\n",
    "    print(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Функция скопирована из `preprocess_data.ipynb`\n",
    "\n",
    "def combine_features(features_groups,\n",
    "                     exclude_features):\n",
    "    '''features_groups - объединить эти группы признаков\n",
    "       exclude_features  - исключить эти признаки\n",
    "    '''\n",
    "    result = list()\n",
    "    for sublist in features_groups:\n",
    "        for item in sublist:\n",
    "            result.append(item)\n",
    "    result = [x for x in result if x not in exclude_features]\n",
    "    return(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Описание эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Название эксперимента, директория для результатов\n",
    "ToDo: журнал экспериментов, отчёт о результатах."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_name = 'Predict_LogisticRegression-GeneticRisk__1_Scaled_2'\n",
    "experiment_dir = '../experiment_dir/' + experiment_name + '/'\n",
    "!md \"{experiment_dir}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отбор признаков для моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Целевой признак\n",
    "target_features = features['target']       \n",
    "print(target_features)\n",
    "y   = np.array(df[target_features]).T[0]\n",
    "y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Без генетических факторов\n",
    "model_0_features = combine_features(\n",
    "                       [\n",
    "                        # target_features, \n",
    "                        features['relatives'],        # Макс. target у родственников\n",
    "                        features['sex'],              # Пол\n",
    "                        [features['bmi_scaled'][0]],  # BMI_scaled\n",
    "                        features['symptom'],          # ККФ: кольцо Кайзера-Флейшера\n",
    "                        [  features['cirrhosis'][0],   # 0: Cirrhosis, 1: ChildPugh, 2: Advanced\n",
    "                        #   features['cirrhosis'][1]\n",
    "                        #  # features['cirrhosis'][2]\n",
    "                           features['childpugh_dummy'][1],\n",
    "                         ],\n",
    "                        features['activity'],         \n",
    "                        features['debut_age_scaled'],\n",
    "                        features['debut_organ'],      # Дебют, кроме неврологического\n",
    "                        ],\n",
    "                       features['exclude_model'])\n",
    "print(model_0_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ext[model_0_features].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# С генетическими факторами\n",
    "\n",
    "#model_genetic_features = features['genetic_risk__1_scaled']\n",
    "#model_genetic_features = [features['genetic_risk__1_scaled'][0]]\n",
    "\n",
    "#model_genetic_features = features['genetic_risk__1']\n",
    "model_genetic_features = [ features['genetic_risk__1'][0] ]\n",
    "\n",
    "print( model_genetic_features )\n",
    "\n",
    "model_features = combine_features(\n",
    "                       [  model_0_features,\n",
    "                          model_genetic_features\n",
    "                        ],\n",
    "                       features['exclude_model'])\n",
    "print(model_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем генетические признаки и цирроз\n",
    "# Выбор масштаба\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "scaler = MinMaxScaler()\n",
    "scaler_st = StandardScaler()\n",
    "\n",
    "#X   = pd.DataFrame(scaler_st.fit_transform(X), columns=X.columns)\n",
    "\n",
    "\n",
    "# Cirrhosis features\n",
    "df[features['cirrhosis']] = scaler_st.fit_transform(df[features['cirrhosis']])\n",
    "\n",
    "\n",
    "# Genetic features\n",
    "#f_val        = df.loc[:, [model_genetic_features[0]]]\n",
    "f_val        = df.loc[:, model_genetic_features]\n",
    "up_quantiles = f_val.quantile(0.95)\n",
    "up_outliers  = (f_val > up_quantiles)\n",
    "f_crop       = f_val.mask(up_outliers, up_quantiles, axis=1)\n",
    "\n",
    "scaler.fit(f_crop)\n",
    "f_scaled     = pd.DataFrame(scaler.transform(f_val))\n",
    "f_scaled.columns = model_genetic_features\n",
    "\n",
    "#scale_genetic_features = 1       # 13 признаков\n",
    "scale_genetic_features = 2        # 13 признаков\n",
    "#scale_genetic_features = 3       #  3 признака: DebutLiver, GenRisk__1, Sex\n",
    "#scale_genetic_features = 5       #  3 признака: DebutLiver, GenRisk__1, Sex\n",
    "#scale_genetic_features = 10      #  3 признака: DebutLiver, GenRisk__1, Sex\n",
    "f_scaled     = f_scaled.multiply(scale_genetic_features)\n",
    "\n",
    "#scale_2 = 10\n",
    "#f_scaled.loc[:,('GenProtect__1')] = f_scaled.loc[:,('GenProtect__1')].multiply(scale_2)\n",
    "\n",
    "print(model_genetic_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df[model_features]\n",
    "\n",
    "X.loc[:,model_genetic_features] =  np.array(f_scaled)\n",
    "\n",
    "X[model_genetic_features].head(4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Без генетических факторов\n",
    "# X_0 = df[model_0_features]\n",
    "X_0 = X[model_0_features]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.hist(f_scaled.T)\n",
    "#\n",
    "#plt.hist(np.array(X.loc[:,(model_genetic_features)]).T[0])\n",
    "#plt.xlabel(model_genetic_features[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_genetic_features[0]\n",
    "model_genetic_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[target_features + model_features].to_csv(experiment_dir + 'model_features.csv')\n",
    "df[target_features + model_0_features].to_csv(experiment_dir + 'model_0_features.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Проведение эксперимента"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Оптимизация параметров и оценка качества моделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model    import LinearRegression, LogisticRegression, LassoCV, Lasso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold = StratifiedKFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "# param_grid = { 'C': np.logspace(-6, 2, 200) }\n",
    "param_grid = { 'C': np.logspace(-6, 2, 17) }\n",
    "param_grid = { 'C': np.logspace(-6, 2, 25) }\n",
    "param_grid = { 'C': np.logspace(-6, 2, 33) }\n",
    "param_grid = { 'C': np.logspace(-6, 2, 49) }\n",
    "param_grid = { 'C': np.logspace(-6, 2, 65) }\n",
    "param_grid = { 'C': np.logspace(-6, 2, 97) }\n",
    "param_grid = { 'C': np.logspace(-6, 2, 129) }\n",
    "#param_grid = { 'C': np.logspace(-6, 2, 193) }\n",
    "#param_grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "grid_searcher = GridSearchCV(                     # For model with genetic features\n",
    "    estimator = LogisticRegression(random_state=42, penalty = 'l1'),\n",
    "    param_grid = param_grid,\n",
    "    scoring = 'roc_auc',\n",
    "    cv = kfold, n_jobs=1)\n",
    "\n",
    "grid_searcher.fit(X, y)\n",
    "print('grid_searcher.fit(X, y) best score:', grid_searcher.best_score_, grid_searcher.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "grid_searcher_0 = GridSearchCV(                  # For model without genetic features\n",
    "    estimator=LogisticRegression(random_state=42, penalty = 'l1'),\n",
    "    param_grid= param_grid,\n",
    "    scoring = 'roc_auc',\n",
    "    cv=kfold, n_jobs=1)\n",
    "\n",
    "grid_searcher_0.fit(X_0, y)\n",
    "print('grid_searcher_0.fit(X_0, y) best score:', grid_searcher_0.best_score_, grid_searcher_0.best_params_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Зависимость ROC AUC от параметра регуляризации C = $1/\\gamma$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results   = pd.DataFrame(grid_searcher.cv_results_)\n",
    "results_0 = pd.DataFrame(grid_searcher_0.cv_results_)\n",
    "\n",
    "#   plt.plot(results['param_C'],   results['mean_train_score'],   label= 'X:  train ROC AUC')\n",
    "plt.semilogx(results['param_C'],   results['mean_test_score'],    label= 'Genetic risk used:     test data')\n",
    "\n",
    "#   plt.plot(results_0['param_C'], results_0['mean_train_score'], label= 'X0: train ROC AUC')\n",
    "plt.semilogx(results_0['param_C'], results_0['mean_test_score'],  label= 'Genetic risk ignored: test data')\n",
    "plt.legend(loc='lower center');\n",
    "plt.title('Logistic Regression ROC AUC') \n",
    "ymin, ymax = (0.65, 0.85)\n",
    "plt.ylim( (ymin, ymax) )\n",
    "xmin, xmax = (0.05, 100)\n",
    "plt.xlim( (xmin, xmax) )\n",
    "plt.xlabel('Regualarisation C')\n",
    "plt.ylabel('ROC AUC')\n",
    "\n",
    "#results_0   #.describe().T"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Важность признаков у лучших моеделей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importances(df, grid_searcher, param_grid, model_features, model_type_name, features_set_name):\n",
    "    importances = grid_searcher.best_estimator_.coef_[0]\n",
    "    X   = df[model_features]\n",
    "\n",
    "    indices_abs = np.argsort(np.abs(importances))[::-1]    # Absolute importance\n",
    "    indices_ord = np.argsort(importances)[::-1]            # rank importance\n",
    "\n",
    "    indices = indices_abs\n",
    "    model_features_xticks = [model_features[i] for i in indices]\n",
    "\n",
    "    # Plot the feature importances\n",
    "    plt.figure(figsize=(8,4))\n",
    "    plt.title(\"Feature importances\")\n",
    "    plt.bar( range(X.shape[1]), np.abs(importances[indices]),\n",
    "             color=\"r\", # yerr=std[indices], align=\"center\"\n",
    "           )\n",
    "    plt.xticks(range(X.shape[1]), model_features_xticks, rotation=75)\n",
    "    plt.xlim([-1, X.shape[1]])\n",
    "    plt.title('Важность признаков лучшей модели ' + model_type_name + '\\n' + features_set_name)\n",
    "    plt.show()\n",
    "\n",
    "plot_importances(df, grid_searcher, param_grid, model_features,     \"LogisticRegression\", \"с генетическими факторами риска\")\n",
    "plot_importances(df, grid_searcher_0, param_grid, model_0_features, \"LogisticRegression\",  \"без генетических факторов риска\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def report_importances(grid_searcher, param_grid, model_features, model_type_name, features_set_name):\n",
    "    \n",
    "    # -----------------------------------------------------\n",
    "    # Print featires of the best model\n",
    "    # -----------------------------------------------------\n",
    "    importances = grid_searcher.best_estimator_.coef_[0]\n",
    "    X   = df[model_features]\n",
    "\n",
    "    indices_abs = np.argsort(np.abs(importances))[::-1]    # Absolute importance\n",
    "    indices_ord = np.argsort(importances)[::-1]            # rank importance\n",
    "\n",
    "    #print(\"Feature importance:\")\n",
    "    #indices = indices_abs\n",
    "    #for f in range(len(model_features)):                 #  range(X.shape[1]):\n",
    "    #    if np.abs(importances[indices[f]])>0:\n",
    "    #        print(\"%d. %-20s \\t%f\" % (f + 1, X.columns[indices[f]], importances[indices[f]]))\n",
    "\n",
    "    print(\"\\nВеса признаков для модели \" + model_type_name + \"\\n\" + features_set_name)\n",
    "    \n",
    "    indices = indices_ord            # Вывести отсчёт, сортируя признаки с учётом знака\n",
    "    indices = indices_abs            # Вывести отсчёт, сортируя признаки по абсолютной величине\n",
    "    \n",
    "    important_features = []\n",
    "    for f in range(len(model_features)):                 #  range(X.shape[1]):\n",
    "        if np.abs(importances[indices[f]])>0:\n",
    "            important_features.append(X.columns[indices[f]])\n",
    "            print(\"%d. %-20s \\t%f\" % (f + 1, X.columns[indices[f]], importances[indices[f]]))\n",
    "    \n",
    "    return(important_features)\n",
    "\n",
    "important_features   = report_importances(grid_searcher,   param_grid, model_features,   \n",
    "                                          \"LogisticRegression\", \"с генетическими факторами риска\")\n",
    "\n",
    "important_features_0 = report_importances(grid_searcher_0, param_grid, model_0_features, \n",
    "                                          \"LogisticRegression\",  \"без генетических факторов риска\")\n",
    "\n",
    "print('\\n', important_features)\n",
    "print('\\n', important_features_0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Зависимость коэффцицентов модели от параметра регуляризации C = $1/\\gamma$\n",
    "\n",
    "Оптимизируем $C \\cdot \\sum  LogLoss(i) + \\sum |w_i|$. \n",
    "<br> - Большая $C$: доминирует $\\sum LogLoss$ - слабая регуляризация.\n",
    "<br> - Малая $C$: доминирует $\\sum |w_i|$ - сильная регуляризация.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_importances_path(grid_searcher, param_grid, model_features, model_type_name, features_set_name):\n",
    "    importances = grid_searcher.best_estimator_.coef_[0]\n",
    "    X   = df[model_features]\n",
    "\n",
    "    indices_abs = np.argsort(np.abs(importances))[::-1]    # Absolute importance\n",
    "    indices_ord = np.argsort(importances)[::-1]            # rank importance\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Generate data\n",
    "    # -----------------------------------------------------\n",
    "    coefs   = []\n",
    "    estimator=LogisticRegression(random_state=42, penalty = 'l1')\n",
    "    for C in param_grid[\"C\"]:\n",
    "        params = {\"C\":C}\n",
    "        estimator.set_params(**params)\n",
    "        estimator.fit(X, y)\n",
    "        coef_ = estimator.coef_[0]\n",
    "        coefs.append(coef_)\n",
    "\n",
    "    # -----------------------------------------------------\n",
    "    # Graphics\n",
    "    # -----------------------------------------------------\n",
    "    ax = plt.gca()\n",
    "    indices = indices_ord\n",
    "    for f in range(len(model_features)):\n",
    "        i = indices[f]\n",
    "        feature = model_features[i]\n",
    "        feature_data = np.array(coefs).T.tolist()[i]\n",
    "        if np.abs(importances[indices[f]])>0:\n",
    "            ax.plot(param_grid[\"C\"], feature_data, label=feature)\n",
    "        else:\n",
    "            ax.plot(param_grid[\"C\"], feature_data)\n",
    "\n",
    "    ax.set_prop_cycle(cycler('color', \n",
    "                          ['b', 'r', 'g', 'c', 'k', 'y', 'm']))\n",
    "\n",
    "    ax.set_xscale('log')\n",
    "    plt.xlabel('Коэффициент регуляризации C')\n",
    "    plt.ylabel('Коэффциенты модели')\n",
    "    plt.title('Важность признаков\\nмоделей ' + model_type_name + '\\n' + features_set_name)\n",
    "    \n",
    "    ax.set_xlim(left=0.01, right=grid_searcher.best_params_[\"C\"])   # Диапазон по оси x   100)\n",
    "    ax.set_ylim(bottom=-3, top=2)                                   # Диапазон по оси y\n",
    "\n",
    "    # Put a legend to the right: https://stackoverflow.com/questions/4700614/how-to-put-the-legend-out-of-the-plot\n",
    "    box = ax.get_position()      # print(\"box: \", box)\n",
    "    ax.set_position([box.x0, box.y0, box.width * 0.8, box.height * 0.6]) # Shrink current axis to 80% (x) and 60% (y).\n",
    "    ax.legend()\n",
    "    ax.legend(loc='center left', bbox_to_anchor=(1, 0.50))\n",
    "\n",
    "    ax.minorticks_on             # Grid at minor ticks\n",
    "    ax.grid(True, which='both')\n",
    "\n",
    "    plt.show();\n",
    "# -----------------------------------------------------------------\n",
    "\n",
    "plot_importances_path(grid_searcher,   param_grid, model_features,   \"LogisticRegression\", \"с генетическими факторами риска\")\n",
    "plot_importances_path(grid_searcher_0, param_grid, model_0_features, \"LogisticRegression\",  \"без генетических факторов риска\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Leave-one-out cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score, cross_val_predict, LeaveOneOut, KFold, ShuffleSplit\n",
    "from sklearn.metrics import roc_auc_score, roc_curve\n",
    "from sklearn.metrics import auc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "name  = \"Genetic risk factors included.\"\n",
    "clf = LogisticRegression(random_state=42, penalty = 'l1', C=grid_searcher.best_params_[\"C\"] ) #C=0.38311868495572848) \n",
    "cv_predictions = cross_val_predict(clf, X, y,\n",
    "                                       method='predict_proba',\n",
    "                                       cv=LeaveOneOut()\n",
    "                                       #cv = kfold\n",
    "                                  ) #  cv=10)\n",
    "\n",
    "\n",
    "name_0  = \"Genetic risk factors ignored.\"\n",
    "clf_0 = LogisticRegression(random_state=42, penalty = 'l1', C=grid_searcher_0.best_params_[\"C\"])\n",
    "cv_predictions_0 = cross_val_predict(clf_0, X_0, y,\n",
    "                                       method='predict_proba',\n",
    "                                       cv=LeaveOneOut()\n",
    "                                       #cv = kfold\n",
    "                                    ) #  cv=10)\n",
    "\n",
    "fpr,   tpr,   thresh = roc_curve(y, cv_predictions[: ,1],   drop_intermediate=False)\n",
    "fpr_0, tpr_0, thresh = roc_curve(y, cv_predictions_0[: ,1], drop_intermediate=False)\n",
    "    \n",
    "figure(figsize=(8,8))\n",
    "plt.plot([0,1],[0,1],color='darkgray')\n",
    "plt.plot([0,0],[0,1],color='darkgray')\n",
    "plt.plot([0,1],[0,0],color='darkgray')\n",
    "plt.plot([0,1],[1,1],color='darkgray')\n",
    "plt.plot([1,1],[0,1],color='darkgray')\n",
    "\n",
    "plt.plot(fpr,   tpr,   label= name  \n",
    "                              + ' ROC AUC=' + str( round(auc(fpr,   tpr  )*1000)/1000. ) )\n",
    "plt.plot(fpr_0, tpr_0, label= name_0\n",
    "                              + '  ROC AUC=' + str( round(auc(fpr_0, tpr_0)*1000)/1000. ) )\n",
    "\n",
    "xlabel('False Positive Rate')\n",
    "ylabel('True Positive Rate')\n",
    "title('ROC кривые для Logistic Regression')\n",
    "legend(loc='lower center');\n",
    "\n",
    "plt.savefig(experiment_dir + 'LogRegression.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Сравнение предсказаний"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pred_sorted   = -numpy.sort(-cv_predictions[:,1])\n",
    "#pred_0_sorted = -numpy.sort(-cv_predictions_0[:,1])\n",
    "pred_diff = cv_predictions[:,1] - cv_predictions_0[:,1]\n",
    "\n",
    "pred_array = np.array([\n",
    "    #list(range(pred_length)),\n",
    "    cv_predictions_0[:,1],\n",
    "    cv_predictions[:,1],\n",
    "    pred_diff[:]\n",
    "    ]).transpose()\n",
    "\n",
    "print(len(pred_array))\n",
    "\n",
    "pred_array_sorted_0 = pred_array[pred_array[:,0].argsort()]\n",
    "pred_array_sorted   = pred_array[pred_array[:,1].argsort()]\n",
    "\n",
    "#plt.scatter( x=range(len(pred_array_sorted_0)), y=pred_array_sorted_0[:,0])\n",
    "#plt.scatter( x=range(len(pred_array_sorted_0)), y=pred_array_sorted_0[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 4))\n",
    "#plt.subplots(1,2, figsize=(12, 4))\n",
    "#plt.subplots(2,1, figsize=(6, 8))\n",
    "\n",
    "# plt.subplot(1,2,1)\n",
    "plt.scatter( x=range(len(pred_array_sorted_0)), y=pred_array_sorted_0[:,1], color = 'tab:blue', label='Genetic risk factors',    s=15)\n",
    "plt.scatter( x=range(len(pred_array_sorted_0)), y=pred_array_sorted_0[:,0], color = 'tab:red',  label='No genetic risk factors', s=15)\n",
    "#\n",
    "#plt.scatter(range(pred_length), pred_sorted,   color = 'tab:blue',  label='Genetic risk factors', s=15)\n",
    "#plt.scatter(range(pred_length), pred_0_sorted, color = 'tab:red', label='No genetic risk factors', s=15)\n",
    "plt.legend()\n",
    "plt.title(\"Оценки вероятности: P,  P0\")\n",
    "plt.xlabel(\"Rank,  Rank0\\n\")\n",
    "plt.ylabel(\"P,  P0\")\n",
    "\n",
    "#plt.subplot(1,2,2)\n",
    "#plt.axhline(y=0, color='darkgrey', linestyle='-',linewidth=1)\n",
    "#\n",
    "#p = plt.scatter(cv_predictions_0[:,1],               # pred_0_sorted, \n",
    "#                pred_diff, s=15)\n",
    "#plt.title(\"Разность оценок вероятности: P - P0\")\n",
    "#plt.xlabel(\"P0\")                                  # plt.xlabel(\"P0\")\n",
    "#plt.ylabel(\"P - P0\")\n",
    "#p.set_sizes(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Кластеризация данных, взвешенных с помощью важности признаков"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Features scaled with importances\n",
    "importances   = grid_searcher.best_estimator_.coef_[0]\n",
    "importances_0 = grid_searcher_0.best_estimator_.coef_[0]\n",
    "\n",
    "X_scaled = np.array(X).dot(np.diag(importances))\n",
    "X_0_scaled = np.array(X_0).dot(np.diag(importances_0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Масштабируем выборку с помощью StandardScaler с параметрами по умолчанию.\n",
    "# scaler = StandardScaler()\n",
    "# X_scaled = scaler.fit_transform(X)\n",
    "# X_0_scaled = scaler.fit_transform(X_0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Понижаем размерность с помощью PCA, оставляя столько компонент, сколько нужно, чтобы \n",
    "# объяснить как минимум 90% дисперсии исходных (отмасштабированных) данных. \n",
    "# Используем отмасштабированную выборку и фиксируем random_state (константа RANDOM_STATE).\n",
    "\n",
    "RANDOM_STATE=1543\n",
    "\n",
    "pca     = PCA(n_components=0.9, random_state=RANDOM_STATE).fit(X_scaled)\n",
    "X_pca   = pca.transform(X_scaled)\n",
    "\n",
    "pca_0   = PCA(n_components=0.9, random_state=RANDOM_STATE).fit(X_0_scaled)\n",
    "X_0_pca = pca_0.transform(X_0_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(1,2, figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1,2,1)\n",
    "plt.scatter(X_0_pca[:,0], X_0_pca[:,1], c=y, alpha=0.15, cmap = 'jet')\n",
    "plt.title(\"Группировка без генетических признаков\")\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "#X_plt_dat = np.round( X_pca.transpose(), 2)\n",
    "plt.scatter(X_pca[:,0],   X_pca[:,1], c=y, alpha=0.15, cmap = 'jet')\n",
    "plt.title(\"Группировка с использованием \\n генетических признаков\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_classes = 2\n",
    "kmeans = KMeans(n_clusters=n_classes, n_init=100, \n",
    "                random_state=RANDOM_STATE, n_jobs=1)\n",
    "kmeans.fit(X_pca)\n",
    "cluster_labels = kmeans.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#n_classes = 4\n",
    "#RANDOM_STATE=123\n",
    "#kmeans_0 = KMeans(n_clusters=n_classes, n_init=100, \n",
    "#                  init = np.array([[-0.7,  0.6],  [-0.5,-0.2], [0.9,0.85], [1,0.05]], np.float64),\n",
    "#                  random_state=RANDOM_STATE, n_jobs=1)\n",
    "\n",
    "n_classes = 2\n",
    "kmeans_0 = KMeans(n_clusters=n_classes, n_init=100, \n",
    "                random_state=RANDOM_STATE, n_jobs=1)\n",
    "\n",
    "kmeans_0.fit(X_0_pca[:,0:2])\n",
    "cluster_0_labels = kmeans_0.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplots(3,2, figsize=(10, 11))\n",
    "\n",
    "plt.subplot(3,2,1)\n",
    "plt.scatter(X_0_pca[:,0], X_0_pca[:,1], c=y, alpha=0.15, cmap = 'jet')\n",
    "plt.title(\"Группировка без \\n генетических признаков\")\n",
    "\n",
    "plt.subplot(3,2,2)\n",
    "#X_plt_dat = np.round( X_pca.transpose(), 2)\n",
    "plt.scatter(X_pca[:,0],   X_pca[:,1], c=y, alpha=0.15, cmap = 'jet')\n",
    "plt.title(\"Группировка с использованием \\n генетических признаков\")\n",
    "\n",
    "\n",
    "plt.subplot(3,2,3)\n",
    "plt.scatter(X_0_pca[:, 0], X_0_pca[:, 1], c=-cluster_0_labels, s=20,  cmap='jet');\n",
    "plt.title(\"Поставим вручную метки классов\")\n",
    "\n",
    "plt.subplot(3,2,4)\n",
    "plt.scatter(X_pca[:, 0], X_pca[:, 1],     c=-cluster_labels,   s=20,  cmap='jet');\n",
    "plt.title(\"Поставим вручную метки классов\")\n",
    "\n",
    "plt.subplot(3,2,5)\n",
    "plt.scatter(-X_0['DebutLiver'], X_0['TargetHeadRelativeMax'], c=y, s=20, alpha=0.15,  cmap='jet');\n",
    "plt.title(\"x: -DebutLiver,   y: TargetHeadRelativeMax\")\n",
    "\n",
    "plt.subplot(3,2,6)\n",
    "plt.scatter(-X['DebutLiver'],     X[model_genetic_features[0]], c=y, s=20, alpha=0.15, cmap='jet');\n",
    "plt.title(\"x: -DebutLiver,   y: \" + model_genetic_features[0])\n",
    "\n",
    "\n",
    "plt.savefig(experiment_dir + 'LogRegression_Clustering.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "exclude_features = features['exclude']\n",
    "\n",
    "df_pca = df[combine_features([ target_features, important_features ], exclude_features)]\n",
    "df_pca['cluster_labels'] = cluster_labels\n",
    "\n",
    "outfile = open(experiment_dir + './Wilson_pca.csv', 'w')\n",
    "df_pca.to_csv(outfile, sep=';', index=False, encoding='utf-8', chunksize=1)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pca_0 = df[combine_features([ target_features, important_features_0 ], exclude_features)]\n",
    "df_pca_0['cluster_0_labels'] = cluster_0_labels\n",
    "df_pca_0\n",
    "\n",
    "outfile = open(experiment_dir + './Wilson_0_pca.csv', 'w')\n",
    "df_pca.to_csv(outfile, sep=';', index=False, encoding='utf-8', chunksize=1)\n",
    "outfile.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrap доверительные интервалы"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "\n",
    "def compare_bootstrap_predictions(df, model_0_features, model_features, target_features,\n",
    "                                  clf_0, clf, \n",
    "                                  cat_features=[], n_samples=100, n_splits=10):\n",
    "    \n",
    "    X_0 = df[model_0_features]\n",
    "    X   = df[model_features]\n",
    "    y   = np.array(df[target_features]).T[0]\n",
    "    \n",
    "    sample_size = X.shape[0]\n",
    "    predictions   = np.zeros((n_samples, sample_size))\n",
    "    predictions_0 = np.zeros((n_samples, sample_size))\n",
    "    i_split = 0\n",
    "    for train_indices, test_indices in KFold(n_splits=n_splits, \n",
    "                                             shuffle=True, random_state=1543).split(X):\n",
    "        i_split = i_split+1;\n",
    "        #print('i_split:',i_split)\n",
    "        \n",
    "        boot_test_X_0 = X_0.loc[test_indices]\n",
    "        boot_test_X   = X.loc[  test_indices]\n",
    "\n",
    "        # Таблица индексов для всех bootstrap выборок\n",
    "        boot_train_indices = np.random.choice(train_indices, size=(n_samples, train_indices.shape[0]))\n",
    "        \n",
    "        for sample_id in range(n_samples):\n",
    "            boot_train_X_0 = X_0.loc[boot_train_indices[sample_id]]\n",
    "            boot_train_X   = X.loc[  boot_train_indices[sample_id]]\n",
    "            boot_train_y   = y[boot_train_indices[sample_id]]\n",
    "            \n",
    "            if type(clf).__name__ == 'CatBoostClassifier':\n",
    "                clf_0.fit(boot_train_X_0, boot_train_y, cat_features=cat_features, logging_level='Silent')\n",
    "                clf.fit(  boot_train_X,   boot_train_y, cat_features=cat_features, logging_level='Silent')\n",
    "            else:\n",
    "                clf_0.fit(boot_train_X_0, boot_train_y)\n",
    "                clf.fit(  boot_train_X,   boot_train_y)\n",
    "\n",
    "            predictions_0[sample_id, test_indices] = clf_0.predict_proba(boot_test_X_0)[:,1]\n",
    "            predictions[  sample_id, test_indices] = clf.predict_proba(  boot_test_X)[:,1]\n",
    "\n",
    "    return (predictions_0, predictions)\n",
    "\n",
    "\n",
    "def make_bootstrap_predictions(X, y, clf, cat_features=[], n_samples=100, n_splits=10):\n",
    "    sample_size = X.shape[0]\n",
    "    predictions = np.zeros((n_samples, sample_size))\n",
    "    i_split = 0\n",
    "    for train_indices, test_indices in KFold(n_splits=n_splits).split(X):\n",
    "        i_split = i_split+1;\n",
    "        #print('i_split:',i_split)\n",
    "        \n",
    "        boot_test_X = X.loc[test_indices]\n",
    "\n",
    "        # Таблица индексов для всех bootstrap выборок\n",
    "        boot_train_indices = np.random.choice(train_indices, size=(n_samples, train_indices.shape[0]))\n",
    "\n",
    "        for sample_id in range(n_samples):\n",
    "            boot_train_X = X.loc[boot_train_indices[sample_id]]\n",
    "            boot_train_y = y[boot_train_indices[sample_id]]\n",
    "            if type(clf).__name__ == 'CatBoostClassifier':\n",
    "                clf.fit(boot_train_X, boot_train_y, cat_features=cat_features, logging_level='Silent')\n",
    "                predictions[sample_id, test_indices] = clf.predict_proba(boot_test_X)[:,1]\n",
    "                # predictions[sample_id, test_indices] = clf.predict(boot_test_X)\n",
    "            else:\n",
    "                clf.fit(boot_train_X, boot_train_y)\n",
    "                predictions[sample_id, test_indices] = clf.predict_proba(boot_test_X)[:,1]\n",
    "            \n",
    "    return predictions\n",
    "\n",
    "\n",
    "def count_roc_aucs(y, predictions):\n",
    "    samples_count = predictions.shape[0]\n",
    "    result = np.zeros(samples_count)\n",
    "    for i in range(samples_count):\n",
    "        result[i] = roc_auc_score(y, predictions[i])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "predictions_0, predictions = compare_bootstrap_predictions(\n",
    "    df, model_0_features, model_features, target_features, \n",
    "    clf_0, clf, cat_features=[], n_samples=1000, n_splits=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rocs_0 = count_roc_aucs(y, predictions_0)\n",
    "rocs   = count_roc_aucs(y, predictions)\n",
    "rocs_diff = [rocs[i] - rocs_0[i] for i in range(len(rocs))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "bins = np.linspace(-0.03, 0.14, 1+np.round((0.14 - (-0.03))/0.005))\n",
    "bins\n",
    "#1+np.round((0.14 - (-0.03))/0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "p121 = plt.subplot(121)\n",
    "bins = np.linspace(0.6, 0.9, 21)\n",
    "n, b, p    = pyplot.hist(rocs,   bins, normed = True, alpha=0.5, label='С генетическими признаками')\n",
    "n0, b0, p0 = pyplot.hist(rocs_0, bins, normed = True, alpha=0.5, label='Без генетических признаков')\n",
    "pyplot.legend(loc='upper left')\n",
    "#plt.title('Статистическая (bootstrap) оценка ROC AUC для \\n моделей с генетичесими признаками и без')\n",
    "p121.set_title('Статистическая (bootstrap) оценка ROC AUC для \\n моделей с генетичесими признаками и без',fontsize=12)\n",
    "pyplot.xlabel('ROC AUC')\n",
    "pyplot.ylabel('Частота  ROC AUC')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,20])\n",
    "\n",
    "p122 = plt.subplot(122)\n",
    "#bins = np.linspace(-0.02, 0.14, 21)\n",
    "xmin = -0.02\n",
    "xmax = 0.13\n",
    "step = 0.01\n",
    "bins = np.linspace(xmin, xmax, 1+np.round((xmax - xmin)/step))\n",
    "\n",
    "plt.hist(rocs_diff, bins, alpha = 0.65, normed=1)\n",
    "#plt.title('Статистическая оценка разности ROC AUC для \\n моделей с генетичесими признаками и без')\n",
    "p122.set_title('Bootsrap-разности ROC AUC для \\n моделей с генетичесими признаками и без',fontsize=12)\n",
    "plt.ylabel('Частота  разности')\n",
    "plt.xlabel('Разность ROC AUC')\n",
    "axes = plt.gca()\n",
    "axes.set_ylim([0,20])\n",
    "\n",
    "#plt.show()\n",
    "\n",
    "plt.savefig(experiment_dir + 'ROC_AUC_diff.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(rocs_diff, alpha = 0.75, normed=1)\n",
    "plt.title('Статистическая оценка разности ROC AUC для \\n моделей с генетичесими признаками и без')\n",
    "plt.ylabel('Частота')\n",
    "plt.xlabel('Разность ROC AUC')\n",
    "pyplot.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Доверительный интервал для tpr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions.shape\n",
    "#np.around(fpr, 5)\n",
    "\n",
    "predictions.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_tpr_bounds(y, predictions):\n",
    "    \n",
    "    result = []\n",
    "    roc_dict = dict()\n",
    "    for i in range(predictions.shape[0]):\n",
    "        fpr, tpr, thresh = roc_curve(y, predictions[i], drop_intermediate=False)\n",
    "        fpr = np.around(fpr, 5)\n",
    "        tpr = np.around(tpr, 5)\n",
    "        #print(i)\n",
    "        for j in range(len(tpr)):\n",
    "            #if(fpr[j]==0):\n",
    "            #    print(fpr[j], tpr[j])\n",
    "            if fpr[j] in roc_dict.keys():\n",
    "                roc_dict[fpr[j]].append(tpr[j])\n",
    "            else:\n",
    "                roc_dict[fpr[j]] = [tpr[j]]\n",
    "\n",
    "    for f in sorted(roc_dict):\n",
    "        t = roc_dict[f]\n",
    "        tpr_low  = np.percentile(t, q=2.5, axis=0)\n",
    "        tpr_med  = np.percentile(t, q=50, axis=0)\n",
    "        tpr_up   = np.percentile(t, q=97.5, axis=0)\n",
    "        result.append([f, tpr_low, tpr_med, tpr_up])  \n",
    "    \n",
    "    result = np.array(result)\n",
    "    return(result, roc_dict)\n",
    "\n",
    "roc_0_bounds, roc_0_dict = get_tpr_bounds(y, predictions_0)\n",
    "roc_bounds,   roc_dict   = get_tpr_bounds(y, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "figure(figsize=(5,5))\n",
    "plt.plot([0,1],[0,1],color='darkgray')\n",
    "plt.plot([0,0],[0,1],color='darkgray')\n",
    "plt.plot([0,1],[0,0],color='darkgray')\n",
    "plt.plot([0,1],[1,1],color='darkgray')\n",
    "plt.plot([1,1],[0,1],color='darkgray')\n",
    "\n",
    "\n",
    "plt.fill_between(roc_bounds[:,0],   roc_bounds[:,1],   roc_bounds[:,3],   color='red', alpha=0.2)\n",
    "\n",
    "plt.fill_between(roc_0_bounds[:,0], roc_0_bounds[:,1], roc_0_bounds[:,3], color='navy', alpha=0.2)\n",
    "\n",
    "\n",
    "plt.plot(roc_bounds[:,0], roc_bounds[:,1], \n",
    "         #label= name + ' ROC AUC=' + str( round(auc(fpr__0975,   tpr__0975  )*1000)/1000. )\n",
    "         color = 'red', alpha = 0.12\n",
    "        )\n",
    "\n",
    "plt.plot(roc_bounds[:,0], roc_bounds[:,2], \n",
    "         label='С генетическими признаками',\n",
    "         #label= name + ' ROC AUC=' + str( round(auc(fpr__0975,   tpr__0975  )*1000)/1000. )\n",
    "         color = 'red', alpha = 0.65\n",
    "        )\n",
    "\n",
    "plt.plot(roc_bounds[:,0], roc_bounds[:,3], \n",
    "         #label= name + ' ROC AUC=' + str( round(auc(fpr__0975,   tpr__0975  )*1000)/1000. )\n",
    "         color = 'red', alpha = 0.12\n",
    "        )\n",
    "\n",
    "\n",
    "plt.plot(roc_0_bounds[:,0], roc_0_bounds[:,1], \n",
    "         #label= name + ' ROC AUC=' + str( round(auc(fpr__0975,   tpr__0975  )*1000)/1000. )\n",
    "         color = 'navy', alpha = 0.12\n",
    "        )\n",
    "\n",
    "plt.plot(roc_0_bounds[:,0], roc_0_bounds[:,2], \n",
    "         label='Без генетических признаков',\n",
    "         #label= name + ' ROC AUC=' + str( round(auc(fpr__0975,   tpr__0975  )*1000)/1000. )\n",
    "         color = 'navy', alpha = 0.75\n",
    "        )\n",
    "\n",
    "plt.plot(roc_0_bounds[:,0], roc_0_bounds[:,3], \n",
    "         #label= name + ' ROC AUC=' + str( round(auc(fpr__0975,   tpr__0975  )*1000)/1000. )\n",
    "         color = 'navy', alpha = 0.12\n",
    "        )\n",
    "\n",
    "plt.title('Доверительный коридор 95% для ROC кривых')\n",
    "plt.legend(loc=(0.25, 0.07))  # 'lower right')\n",
    "\n",
    "\n",
    "plt.savefig(experiment_dir + 'ROC_corridor.png', bbox_inches='tight')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выводы\n",
    "* Комбинированный генетический фактор позволил уточнить ROC AUC: с 0.729 до 0.774. <br> Статистическая достоверность не оценивалась.\n",
    "* При малых значениях параметра регяляризации $C = 1/\\gamma$, лучшее ROC AUC -- у предсказателя, использующего генетические факторы риска, а при больших сравнение неоднозначно: лучше то один, то другой предсказатель.\n",
    "* Признаки моделей LogisticRegression с наибольшей ROC AUC:\n",
    "    * с использованием генетических факторов риска: <br> GenRisk\\_\\_2 (0.43), DebutAge_scaled (0.05), Activity (-0.1), Sex (-0.25),  DebutLiver (-1.41)\n",
    "    * без использования генетических факторов риска: <br>  TargetHeadRelativeMax (0.99), KKF (0.89), Cirrhosis (0.27), DebutAge_scaled (0.13), Sex (-0.45), Activity (-0.49), DebutLiver (-1.55).\n",
    "* Данные модели с генетическими факторами риска можно  кластеризовать с помощью двух признаков: DebutLiver, GenRisk\\_\\_2. -- оценить качество кластеризации\n",
    "\n",
    "### Особенности вычисления\n",
    "* Развитие цирроза описано с помощью признака Cirrhosis. \n",
    "* Оптимальные параметры сосчитаны с помощью 10-fold cross validation. <br> А измерение качества: leave-one-out cross validation.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features['cirrhosis']].corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features['cirrhosis']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[features['cirrhosis']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df['ChildPugh'], df['Cirrhosis']\n",
    "#y\n",
    "#\n",
    "plt.scatter(df_ext['ChildPugh'][y==0] + np.random.uniform(-0.1, 0.1, size=(51)),\n",
    "            df_ext['Cirrhosis'][y==0] + np.random.uniform(-0.1, 0.1, size=(51)), c='b', alpha = 0.15)\n",
    "plt.scatter(df_ext['ChildPugh'][y==1] + np.random.uniform(-0.1, 0.1, size=(33)),\n",
    "            df_ext['Cirrhosis'][y==1] + np.random.uniform(-0.1, 0.1, size=(33)), c='r',  alpha = 0.15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cirrhosis_count = {}\n",
    "for i in df_ext['ChildPugh'].unique():\n",
    "    cirrhosis_count[i] = {}\n",
    "    for j in df_ext['Cirrhosis'].unique():\n",
    "        cirrhosis_count[i][j] = (len(df_ext[np.logical_and(np.logical_and(df_ext['ChildPugh'] == i,\n",
    "                                                               df_ext['Cirrhosis'] == j),\n",
    "                                                y == 0)]),\n",
    "                              len(df_ext[np.logical_and(np.logical_and(df_ext['ChildPugh'] == i,\n",
    "                                                               df_ext['Cirrhosis'] == j),\n",
    "                                                y == 1)]))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "cirrhosis_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
